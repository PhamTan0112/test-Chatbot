from embedder import get_embedding
from vectorstore import search_similar
import google.generativeai as genai
import requests
from generate_care_plan import generate_care_plan
from predict_specialty import predict_specialty
from db_session import append_session
from symptom_normalizer import normalize_symptom
import re
import json

# Cáº¥u hÃ¬nh API Gemini
genai.configure(api_key="AIzaSyC8hGg01YBuaiyQ9FV73CUU_LFmLI7HdMU")

def call_gemini_flash(prompt: str) -> str:
    model = genai.GenerativeModel("models/gemini-2.0-flash")
    response = model.generate_content(prompt)
    return response.text.strip()

def classify_user_intent(question: str) -> str:
    prompt = f"""
    Báº¡n lÃ  trá»£ lÃ½ y táº¿ thÃ´ng minh. HÃ£y phÃ¢n loáº¡i cÃ¢u há»i sau thÃ nh má»™t trong 3 nhÃ³m:
    - "health_query": náº¿u ngÆ°á»i dÃ¹ng mÃ´ táº£ triá»‡u chá»©ng hoáº·c há»i vá» bá»‡nh
    - "personal_info": náº¿u ngÆ°á»i dÃ¹ng há»i vá» báº£n thÃ¢n (tÃªn, tuá»•i, lá»‹ch khÃ¡m, bÃ¡c sÄ© tá»«ng gáº·p...)
    - "general_chat": náº¿u chá»‰ chÃ o há»i, há»i vu vÆ¡

    Chá»‰ tráº£ vá» Ä‘Ãºng má»™t tá»«: health_query, personal_info hoáº·c general_chat

    CÃ¢u há»i: "{question}"
    """
    try:
        result = call_gemini_flash(prompt)
        return result.strip().lower()
    except Exception:
        return "health_query"

def refine_question_if_needed(question: str) -> str:
    vague_keywords = [
        "má»‡t", "khÃ³ chá»‹u", "khÃ´ng khá»e", "bá»‹ gÃ¬", "nÃªn lÃ m gÃ¬",
        "khÃ´ng á»•n", "tÃ´i cáº£m tháº¥y", "hÆ¡i láº¡", "tháº¥y láº¡", "khÃ³ táº£"
    ]
    if any(kw in question.lower() for kw in vague_keywords):
        question += "\n\nğŸ‘‰ MÃ¬nh cáº§n thÃªm thÃ´ng tin Ä‘á»ƒ giÃºp báº¡n tá»‘t hÆ¡n:\n"
        question += "- Báº¡n cáº£m tháº¥y khÃ´ng khá»e á»Ÿ Ä‘Ã¢u? (vÃ­ dá»¥: Ä‘áº§u, bá»¥ng, ngá»±c...)\n"
        question += "- Triá»‡u chá»©ng báº¯t Ä‘áº§u tá»« khi nÃ o?\n"
        question += "- Má»©c Ä‘á»™ nghiÃªm trá»ng: nháº¹, vá»«a hay dá»¯ dá»™i?"
    return question

def extract_symptoms_with_gemini(question: str) -> list:
    prompt = f'''
Báº¡n lÃ  bÃ¡c sÄ©. TrÃ­ch xuáº¥t táº¥t cáº£ triá»‡u chá»©ng y táº¿ cÃ³ thá»ƒ cÃ³ tá»« cÃ¢u há»i sau. Tráº£ lá»i **chá»‰ dÆ°á»›i dáº¡ng danh sÃ¡ch JSON tiáº¿ng Anh há»£p lá»‡**, khÃ´ng giáº£i thÃ­ch, khÃ´ng dÃ¹ng markdown:
"{question}"

VÃ­ dá»¥ Ä‘áº§u ra: ["headache", "chest pain"]
'''
    try:
        model = genai.GenerativeModel("models/gemini-2.0-flash")
        response = model.generate_content(prompt)
        text = response.text.strip()
        if text.startswith("```"):
            text = re.sub(r"```(?:json)?", "", text, flags=re.IGNORECASE).strip()
            text = text.replace("```", "").strip()
        if not text.startswith("[") or not text.endswith("]"):
            return []
        symptoms = json.loads(text)
        if isinstance(symptoms, list):
            return [s.strip().lower() for s in symptoms if isinstance(s, str)]
    except Exception:
        pass
    return []

def get_standard_symptoms(filepath="documents/benh_va_trieu_chung_chuan_hoa.txt"):
    symptoms_set = set()
    with open(filepath, encoding="utf-8") as f:
        content = f.read()
    blocks = content.split("---")
    for block in blocks:
        symp_match = re.search(r"ğŸ” Biá»ƒu hiá»‡n Ä‘i kÃ¨m:([\s\S]*?)(?:ğŸ›¡ï¸|$)", block)
        if symp_match:
            symptoms = [s.strip().lower() for s in symp_match.group(1).split(",") if s.strip()]
            symptoms_set.update(symptoms)
    return symptoms_set

def load_disease_symptoms(filepath="documents/benh_va_trieu_chung_chuan_hoa.txt"):
    diseases = []
    with open(filepath, encoding="utf-8") as f:
        content = f.read()
    blocks = content.split("---")
    for block in blocks:
        name_match = re.search(r"### [^:]+: (.+)", block)
        desc_match = re.search(r"ğŸ“Œ MÃ´ táº£:([\s\S]*?)(?:ğŸ”|ğŸ›¡ï¸|$)", block)
        symp_match = re.search(r"ğŸ” Biá»ƒu hiá»‡n Ä‘i kÃ¨m:([\s\S]*?)(?:ğŸ›¡ï¸|$)", block)
        if name_match and desc_match and symp_match:
            name = name_match.group(1).strip()
            desc = desc_match.group(1).strip().replace("\n", " ")
            symptoms = [s.strip().lower() for s in symp_match.group(1).split(",") if s.strip()]
            diseases.append({"name": name, "desc": desc, "symptoms": symptoms})
    return diseases

def find_related_diseases(user_symptoms, diseases, min_match=3):
    user_symptoms = [s.strip().lower() for s in user_symptoms]
    related = []
    for d in diseases:
        disease_symptoms = [sym.strip().lower() for sym in d["symptoms"]]
        match_count = sum(1 for s in user_symptoms if s in disease_symptoms)
        if match_count >= min_match:
            related.append({"name": d["name"], "desc": d["desc"], "match": match_count})
    related.sort(key=lambda x: -x["match"])
    return related

def generate_answer(question: str, user_id: str) -> str:
    question = refine_question_if_needed(question)
    question_lower = question.lower()
    intent = classify_user_intent(question)

    # TrÆ°á»ng há»£p há»™i thoáº¡i hoáº·c yÃªu cáº§u cÃ¡ nhÃ¢n
    if intent in ["personal_info", "general_chat"]:
        try:
            res = requests.get(f"http://localhost:3000/api/external/analyze/{user_id}", timeout=5)
            res.raise_for_status()
            data = res.json()
        except Exception:
            return "Xin lá»—i, tÃ´i khÃ´ng thá»ƒ truy xuáº¥t há»“ sÆ¡ bá»‡nh nhÃ¢n lÃºc nÃ y."

        if intent == "general_chat":
            return f"ChÃ o báº¡n {data.get('full_name', 'báº¡n')}! TÃ´i cÃ³ thá»ƒ há»— trá»£ tÆ° váº¥n sá»©c khá»e náº¿u báº¡n cáº§n."

        if intent == "personal_info":
            name = data.get("full_name", "KhÃ´ng rÃµ")
            dob = data.get("dob", "KhÃ´ng rÃµ")
            bp = data.get("blood_pressure", {}).get("text", "ChÆ°a cÃ³ dá»¯ liá»‡u")
            lab = data.get("last_lab_test", "ChÆ°a cÃ³ dá»¯ liá»‡u")
            last_doctor = data.get("last_doctor", {})
            doctor = f"{last_doctor.get('name', 'KhÃ´ng rÃµ')} ({last_doctor.get('specialization', 'ChÆ°a rÃµ')})"
            return (
                f"Báº¡n lÃ  {name}, sinh ngÃ y {dob}. Gáº§n nháº¥t, báº¡n khÃ¡m vá»›i {doctor}. "
                f"Huyáº¿t Ã¡p: {bp}. XÃ©t nghiá»‡m gáº§n nháº¥t: {lab}."
            )

    # Náº¿u lÃ  health_query â†’ tiáº¿p tá»¥c quy trÃ¬nh cháº©n Ä‘oÃ¡n bá»‡nh nhÆ° cÅ©
    raw_symptoms_en = extract_symptoms_with_gemini(question)
    user_symptoms = [normalize_symptom(s) for s in raw_symptoms_en]
    standard_symptoms = get_standard_symptoms()
    user_symptoms = [s for s in user_symptoms if s in standard_symptoms]

    if user_symptoms:
        normalized_query = f"Symptoms: {', '.join(user_symptoms)}. What is the possible disease?"
        query_vec = get_embedding(normalized_query)
    else:
        query_vec = get_embedding(question)

    if not query_vec:
        return "KhÃ´ng thá»ƒ táº¡o embedding cho cÃ¢u há»i."

    docs = search_similar(query_vec)
    if not docs:
        return "Hiá»‡n táº¡i há»‡ thá»‘ng khÃ´ng tÃ¬m tháº¥y tÃ i liá»‡u liÃªn quan Ä‘á»ƒ tÆ° váº¥n. Vui lÃ²ng mÃ´ táº£ rÃµ hÆ¡n hoáº·c thá»­ láº¡i sau."

    try:
        res = requests.get(f"http://localhost:3000/api/external/analyze/{user_id}", timeout=5)
        res.raise_for_status()
        data = res.json()
    except Exception:
        data = {}

    patient_context = data.get("summary_text", "KhÃ´ng cÃ³ dá»¯ liá»‡u bá»‡nh nhÃ¢n.")
    abnormal_flags = data.get("abnormal_flags", [])
    active_doctors = data.get("active_doctors", [])

    predicted_specialty = predict_specialty(question)
    matching_doctors = [
        doc for doc in active_doctors
        if predicted_specialty.lower() in doc.get("specialization", "").lower()
    ] if predicted_specialty != "KhÃ´ng rÃµ" else []

    show_doctors = matching_doctors if matching_doctors else active_doctors
    doctor_list = "\n".join([
        f"{doc.get('name', 'KhÃ´ng rÃµ')} ({doc.get('specialization', 'ChuyÃªn khoa chÆ°a rÃµ')})"
        for doc in show_doctors[:3]
    ]) or "KhÃ´ng cÃ³ dá»¯ liá»‡u bÃ¡c sÄ©"

    diseases = load_disease_symptoms()
    related_diseases = find_related_diseases(user_symptoms, diseases)
    likely_disease = next((d for d in related_diseases if d["match"] >= 3), None)
    disease_summary_details = "\n".join([
        f"- {d['name']}: {d['desc']}" for d in related_diseases[:2]
    ]) or "ChÆ°a xÃ¡c Ä‘á»‹nh rÃµ"

    prompt = f"""
Báº¡n lÃ  má»™t bÃ¡c sÄ© gia Ä‘Ã¬nh áº£o, nhiá»‡m vá»¥ cá»§a báº¡n lÃ :
1. PhÃ¢n tÃ­ch triá»‡u chá»©ng ngÆ°á»i bá»‡nh cung cáº¥p
2. ÄÆ°a ra má»™t sá»‘ bá»‡nh lÃ½ cÃ³ thá»ƒ liÃªn quan
3. Dá»± Ä‘oÃ¡n chuyÃªn khoa nÃªn Ä‘áº¿n khÃ¡m
4. ÄÆ°a ra khuyáº¿n nghá»‹: nÃªn Ä‘i khÃ¡m sá»›m hay theo dÃµi thÃªm
5. Giá»¯ ngá»¯ Ä‘iá»‡u nháº¹ nhÃ ng, Ä‘á»“ng cáº£m, dá»… hiá»ƒu

Ngá»¯ cáº£nh bá»‡nh nhÃ¢n:

ğŸ“¨ CÃ¢u há»i:
"{question}"
ğŸ“‹ Triá»‡u chá»©ng trÃ­ch xuáº¥t:
{', '.join(user_symptoms) if user_symptoms else 'ChÆ°a rÃµ'}
ğŸ“Œ Bá»‡nh nghi ngá»: {likely_disease['name'] if likely_disease else 'ChÆ°a xÃ¡c Ä‘á»‹nh'}
ğŸ§  CÃ¡c bá»‡nh cÃ³ thá»ƒ liÃªn quan:
{disease_summary_details}
ğŸ“ˆ ChuyÃªn khoa phÃ¹ há»£p: {predicted_specialty}
ğŸ” Dáº¥u hiá»‡u báº¥t thÆ°á»ng (náº¿u cÃ³):
{'; '.join(abnormal_flags) if abnormal_flags else 'KhÃ´ng cÃ³'}
ğŸ‘¨â€âš•ï¸ BÃ¡c sÄ© sáºµn cÃ³:
{doctor_list}
ğŸ’¼ Há»“ sÆ¡ bá»‡nh nhÃ¢n:
{patient_context}
ğŸ¯ HÃ£y tráº£ lá»i bá»‡nh nhÃ¢n báº±ng vÄƒn phong tá»± nhiÃªn. Viáº¿t ngáº¯n gá»n, khÃ´ng quÃ¡ 4â€“5 cÃ¢u. TrÃ¡nh liá»‡t kÃª mÃ¡y mÃ³c, khÃ´ng kháº³ng Ä‘á»‹nh cháº©n Ä‘oÃ¡n cháº¯c cháº¯n. HÃ£y há»— trá»£ bá»‡nh nhÃ¢n ra quyáº¿t Ä‘á»‹nh.
"""

    try:
        llm_answer = call_gemini_flash(prompt)
    except Exception:
        llm_answer = "Hiá»‡n táº¡i há»‡ thá»‘ng chÆ°a thá»ƒ táº¡o pháº£n há»“i chi tiáº¿t. DÆ°á»›i Ä‘Ã¢y lÃ  tÆ° váº¥n sÆ¡ bá»™."

    abnormal_section = "\nğŸ”¹ Dáº¥u hiá»‡u báº¥t thÆ°á»ng:\n- " + "\n- ".join(abnormal_flags) if abnormal_flags else ""
    care_plan = generate_care_plan(user_id) if any(kw in question_lower for kw in ["tÃ´i", "cá»§a tÃ´i"]) and abnormal_flags else ""
    care_plan_section = f"\n\nğŸ“‹ Káº¿ hoáº¡ch chÄƒm sÃ³c cÃ¡ nhÃ¢n hÃ³a:\n{care_plan.strip()}" if care_plan else ""

    final_answer = llm_answer + abnormal_section + care_plan_section
    append_session(user_id, question, final_answer)
    return final_answer
